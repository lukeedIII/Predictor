<div align="center">

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="assets/logo-banner.svg">
  <source media="(prefers-color-scheme: light)" srcset="assets/logo-banner.svg">
  <img alt="Nexus Shadow-Quant" src="assets/logo-banner.svg" width="100%">
</picture>

<br/>
<br/>

[![Version](https://img.shields.io/badge/version-7.0.0-6C63FF?style=for-the-badge&labelColor=0D0D0D)](https://github.com/lukeedIII/Predictor)
[![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white&labelColor=0D0D0D)](https://python.org)
[![React](https://img.shields.io/badge/React-19-61DAFB?style=for-the-badge&logo=react&logoColor=white&labelColor=0D0D0D)](https://react.dev)
[![Electron](https://img.shields.io/badge/Electron-40-47848F?style=for-the-badge&logo=electron&logoColor=white&labelColor=0D0D0D)](https://electronjs.org)
[![CUDA](https://img.shields.io/badge/CUDA-Accelerated-76B900?style=for-the-badge&logo=nvidia&logoColor=white&labelColor=0D0D0D)](https://developer.nvidia.com/cuda-toolkit)
[![Tests](https://img.shields.io/badge/Tests-24%20Passing-00D084?style=for-the-badge&labelColor=0D0D0D)](desktop/python_backend/tests/test_core.py)
[![License](https://img.shields.io/badge/License-MIT-F7B731?style=for-the-badge&labelColor=0D0D0D)](LICENSE)

<br/>

> **Nexus Shadow-Quant** is an autonomous, institutional-grade Bitcoin intelligence suite.  
> It ingests live market data, runs a 16-model quant engine, and deploys a self-supervised  
> **Jamba Hybrid SSM** to forecast price direction â€” all running locally on your machine.

<br/>

</div>

---

## âš¡ What It Does â€” At a Glance

| Capability | Detail |
|:-----------|:-------|
| ğŸ§  **Core Model** | **Jamba Hybrid SSM** â€” Mamba blocks + Attention + Mixture of Experts (MoE) |
| ğŸ“ **Prediction Task** | P(BTC up **â‰¥ +0.30%** within 15 minutes) â€” 3-class: UP / FLAT / DOWN |
| ğŸ—ï¸ **Training Set** | Last **500,000** 1-minute candles (~1 year of live data, auto-refreshed) |
| ğŸ“¡ **Data Pipeline** | Binance REST + WebSocket Â· 42 scale-invariant features Â· zero raw-price leakage |
| ğŸ”¬ **Quant Engine** | 16 institutional models: HMM, GJR-GARCH, Heston, Rough Vol, PPO RL, TDA, RQA... |
| ğŸ’¹ **Paper Trader** | Long/short simulation Â· multi-position Â· Kelly sizing Â· fee-adjusted PnL |
| ğŸ¤– **Dr. Nexus AI** | Branded analyst â€” OpenAI â†’ Gemini â†’ Ollama â†’ embedded Qwen 0.5B fallback |
| ğŸ–¥ï¸ **Dashboard** | Electron + React Â· drag-and-drop grid Â· WebSocket push Â· light/dark theme |

---

## ğŸ“¸ Platform Overview

<div align="center">

<img src="assets/demo.gif" alt="Nexus Shadow-Quant Dashboard" width="100%">

<p><em>Real-time BTC forecasting Â· 16-model Quant Intelligence Â· Dr. Nexus AI Analyst</em></p>

</div>

---

## ğŸ§¬ The Prediction Target (Exactly)

This is **not** a naive next-candle-up/down classifier.

```
Label Definition  (predictor.py â€” zero ambiguity)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Horizon  : 15 minutes (close-to-close)
UP    = 1 : close[t+15] > close[t] Ã— 1.003    â†’  +0.30% move
DOWN  = 0 : anything else (including small moves < +0.30%)

The +0.30% hurdle â‰ˆ total fees + slippage.
The model learns when a trade is worth taking â€” not just price direction.
```

> The UI surfaces this as **UP / DOWN + Confidence %** via softmax probabilities.

---

## ğŸ›ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Electron Shell                          â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ React Frontend â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PriceCard Â· SignalBadge Â· TradingView Chart              â”‚  â”‚
â”‚  â”‚  Quant Intelligence (16 models) Â· Dr. Nexus AI           â”‚  â”‚
â”‚  â”‚  World Clock Â· Swiss Weather Â· Hardware Monitor          â”‚  â”‚
â”‚  â”‚  Paper Trading (equity curve, PnL) Â· Layout Presets      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚  WebSocket (push ~1s) + REST            â”‚
â”‚                       â”‚  localhost:8420                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                Python Backend (FastAPI + Uvicorn)          â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ DataCollectorâ”‚â†’ â”‚FeatureEngine  â”‚â†’ â”‚  Predictor    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚ (Binance WS) â”‚  â”‚ (42 features) â”‚  â”‚ (Jamba SSM)   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                               â”‚           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         QuantEngine  (16 institutional models)      â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚         PaperTrader  (thread-safe simulation)         â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **100% local.** External calls: Binance (market data) Â· OpenAI/Gemini (optional) Â· HuggingFace (model sync, optional)

---

## ğŸ§  Jamba Hybrid SSM â€” The Core Model

Adapted from the **AI21 Labs Jamba architecture (2024)** for financial time series:

| Component | Role |
|:----------|:-----|
| **Mamba blocks** | O(n) selective state space â€” sequential pattern recognition |
| **Attention blocks** | Global context via Grouped Query Attention (GQA) â€” memory efficient |
| **Mixture of Experts (MoE)** | 4â€“8 experts, top-k routing â€” capacity without compute cost |
| **RMSNorm** | Faster + more numerically stable than LayerNorm |
| **3-class head** | Softmax â†’ P(UP), P(FLAT), P(DOWN) |

### Available Sizes

| Model | Params | VRAM | Architecture | Best For |
|:------|:------:|:----:|:-------------|:---------|
| **SmallJamba** | 4.4M | ~0.2 GB | 3 Mamba + 1 Attn Â· 4 experts (top-1) | Low VRAM Â· fastest inference |
| **LiteJamba** âš—ï¸ | ~12M | ~0.5 GB | 5 Mamba + 1 Attn Â· 4 experts (top-1) | OOD test â€” trained 2021-2026 only |
| **MediumJamba** | ~28M | ~1.2 GB | 6 Mamba + 2 Attn Â· 6 experts (top-2) | Balanced capacity |
| **LargeJamba** ğŸ”¥ | ~60M | ~3.5 GB | 9 Mamba + 3 Attn Â· 8 experts (top-2) | Maximum capacity |

> âš—ï¸ **LiteJamba is deliberately OOD-tested:** trained exclusively on 2021â€“2026 data. The model has **never seen 2018â€“2020**, making that period a true out-of-distribution test of regime generalization.

### Multi-Model Ensemble

Run multiple Jamba variants simultaneously for stronger consensus signals:

```
SmallJamba  â†’  UP (68%)  â”€â”
                           â”œâ”€  Ensemble: UP (71%)  âœ…  High confidence â†’ trade
LiteJamba   â†’  UP (74%)  â”€â”˜

SmallJamba  â†’  UP (55%)  â”€â”
                           â”œâ”€  Ensemble: FLAT  â¸ï¸  Disagreement â†’ skip
LiteJamba   â†’ DOWN (60%) â”€â”˜
```

**GPU memory for common combos:**

| Combination | VRAM |
|:------------|:----:|
| SmallJamba alone | ~0.2 GB |
| Small + Lite | ~0.7 GB |
| Small + Medium | ~1.4 GB |
| Small + Large | ~3.7 GB |
| All four | ~5.4 GB |

### Training Commands

```powershell
cd desktop\python_backend
.\venv\Scripts\Activate.ps1

python train_mamba.py --arch small  --skip-download   # SmallJamba  (4.4M)
python train_mamba.py --arch lite   --skip-download   # LiteJamba   (~12M)
python train_mamba.py --arch medium --skip-download   # MediumJamba (~28M)
python train_mamba.py --arch large  --skip-download   # LargeJamba  (~60M)
python train_mamba.py --arch small  --quick --skip-download  # 60s smoke test
```

Each variant saves as `nexus_{size}_jamba_v1.pth` automatically.

---

## ğŸ“Š Feature Set â€” 42 Scale-Invariant Features

All features are **price-level agnostic**: returns, ratios, and z-scores â€” never raw prices. The exact same `_engineer_features()` function runs at training time and live inference time.

| Family | Features |
|:-------|:---------|
| **Returns & Momentum** | 1m / 5m / 15m / 1h / 4h returns Â· RSI (Kalman-smoothed) Â· volume momentum |
| **Candle Geometry** | High-low range ratio Â· close-open body ratio |
| **Trend Context** | SMA distance ratios Â· multi-timeframe trend flags (5m / 15m / 1h) |
| **Volatility & Risk** | Rolling realized vol Â· GJR-GARCH asymmetry proxy Â· vol regime ratio |
| **Cycles & Fractals** | FFT dominant periods Â· rolling Hurst exponent |
| **Microstructure** | Tick volatility Â· whale ratio Â· buy/sell pressure |
| **Drift & Jumps** | Wasserstein drift Â· Hawkes self-exciting intensity |
| **Cross-Asset** | ETH returns / vol Â· ETH/BTC trend Â· PAXG returns |
| **Live WS Signals** | Trades/sec Â· WS buy-sell ratio Â· spread (bps) |

---

## ğŸ”¬ Quant Intelligence Engine â€” 16 Models

### Used in the Predictor Feature Vector (No Lookahead)

| Feature | Source |
|:--------|:-------|
| Regime ID + confidence | Hurst-based HMM (vectorized) |
| GJR-GARCH volatility | Vectorized rolling fit |
| Hawkes intensity | Self-exciting proxy (vectorized) |
| Wasserstein drift | Distribution shift metric (vectorized) |

### UI Diagnostics â€” Real-Time Institutional Panel

| # | Model | Output |
|:--|:------|:-------|
| 1 | **HMM Regime** | BULL / SIDEWAYS / BEAR + state probabilities |
| 2 | **GJR-GARCH** | Forecast vol Â· asymmetry Î³ Â· conditional vol |
| 3 | **Heston SV** | Current / mean vol Â· leverage Ï |
| 4 | **Rough Vol** | Hurst H Â· roughness score |
| 5 | **OFI** | Buy/sell pressure Â· normalized order flow |
| 6 | **EMD** | Top-3 empirical mode cycle strengths |
| 7 | **HHT** | Dominant frequency Â· period in minutes |
| 8 | **Wavelets** | Trend strength Â· signal vs noise ratio |
| 9 | **Merton Jump** | Detected Â· probability Â· direction Â· risk level |
| 10 | **Bates SVJ** | Jump intensity Â· risk score |
| 11 | **MF-DFA** | Î”H Â· spectral width Â· multifractal interpretation |
| 12 | **TDA** | Persistence Â· complexity Â· topology score |
| 13 | **RQA** | Determinism Â· recurrence rate |
| 14 | **Almgren-Chriss** | Optimal execution trajectory Â· market impact |
| 15 | **PPO RL Agent** | Action distribution (HOLD/BUY/SELL) Â· value |
| 16 | **Basic Metrics** | RSI Â· Momentum Â· Sharpe Â· VWAP distance |

---

## ğŸ’¹ Paper Trading Engine

Fully simulated, zero real orders â€” every parameter is config-driven:

| Parameter | Default | Description |
|:----------|:-------:|:------------|
| **Max concurrent positions** | 3 | Multi-position support |
| **Min confidence gate** | 30% | Adaptive â€” self-adjusts based on recent performance |
| **Position sizing** | Half-Kelly | On available balance |
| **Leverage** | 10Ã— | Configurable |
| **Fees** | 0.04% + 0.01% | Binance taker + slippage (both open and close) |
| **Max hold time** | 2 hours | `PAPER_MAX_HOLD_SEC` |
| **Circuit breaker** | 20% drawdown | Halts trading |
| **Cooldown** | 60 seconds | Min time between trades |

**Exit triggers:** TP/SL (ATR-scaled), trailing stop, prediction flip, max hold, liquidation.

**Accounting:** every trade record includes `gross_pnl_usd`, `pnl_usd` (net of fees), `entry_fee`, `exit_fee`, `total_fee`. Stats expose `net_sharpe_ratio` and cumulative fee drag.

---

## âœ… Engineering Standards (Code-Verified)

<details>
<summary><b>Click to expand full checklist</b></summary>

- âœ… Scale-invariant features â€” returns/ratios only, no raw price leakage
- âœ… Identical feature engineering path for training and live inference
- âœ… Label includes +0.30% hurdle (fee/slippage-aware target)
- âœ… Strict temporal split â€” no shuffle, no future data
- âœ… Exponential recency weighting for market adaptation
- âœ… Probability calibration (Platt scaling)
- âœ… Live prediction validation after 15-minute horizon
- âœ… **Champion-Challenger gate** â€” challenger must match or beat production on logloss + accuracy
- âœ… **Drift monitoring** â€” 3-channel: feature PSI + prediction distribution shift + Brier/ECE calibration
- âœ… **Fee-adjusted net-PnL** â€” gross/net/fee breakdown per trade, total fees in stats
- âœ… **Rolling walk-forward evaluation** â€” K=5 expanding-window folds, logged per retrain
- âœ… **XGBoost early stopping** â€” eval-set logloss, `early_stopping_rounds=30`
- âœ… **Regime-based trade gating** â€” Hurst chaos filter + vol-regime bounds + win-rate gate
- âœ… **Dynamic class-imbalance correction** â€” `scale_pos_weight` = neg/pos ratio per training call
- âœ… **Gap detection + quarantine** â€” gaps >5 min detected, quarantined rows excluded from training
- âœ… **Semantic HMM state ordering** â€” states sorted by mean return for stable BULL/BEAR labels
- âœ… **RQA/TDA computational guardrails** â€” max 200-point windows, vectorized `cdist`
- âœ… **Thread-safe model access** â€” `threading.RLock` for model swap and read
- âœ… **Thread-safe PaperTrader** â€” `threading.RLock` on all balance/position mutations
- âœ… **Bounded feedback log** â€” `deque(maxlen=2000)` prevents unbounded memory growth
- âœ… **Boot-gate middleware** â€” FastAPI holds requests until init completes (120s failsafe)
- âœ… **MoE aux loss propagation** â€” auxiliary loss backpropagated through all Jamba variants
- âœ… **Gradient clipping** â€” `clip_grad_norm_(max_norm=1.0)` in all training loops
- âœ… **Pinned dependency versions** â€” `requirements.txt` uses compatible-range constraints
- âœ… **Backtest horizon alignment** â€” all scripts use `config.PREDICTION_HORIZON_MINUTES`
- âœ… **Hugging Face Model Sync** â€” cloud backup/restore to skip initial training
- âœ… **Drag-and-drop dashboard** â€” react-grid-layout with JSON layout persistence
- âœ… **3 saveable layout presets** + reset to default
- âœ… **Light / Dark theme** â€” CSS variable scoping + localStorage persistence
- âœ… **World Clock** â€” 6 financial hubs (NYSE/LSE/SIX/MOEX/TSE/SSE) with live market status
- âœ… **Swiss Weather widget** â€” live conditions for ZÃ¼rich
- âœ… **Dr. Nexus AI** â€” dual-mode prompting: Analysis Card format + conversational mode
- âœ… **Provider badges** â€” every AI response shows which LLM generated it
- âœ… **Embedded fallback LLM** â€” Qwen2.5-0.5B locally, no API key required
- âœ… **Test suite** â€” 24 pytest tests across 8 areas
- âœ… **Clean MIT license**

</details>

---

## ğŸ“ˆ Performance Benchmark

| Metric | Value | Notes |
|:-------|:-----:|:------|
| Offline backtest accuracy | **50.71%** | Walk-forward, 3.15M candles |
| Sharpe ratio (backtest) | **0.88** | Treat as "promising but modest edge" |
| Prediction latency | **~5 ms** | GPU (RTX 3060+) |
| Training time | **~6 hrs** | 500K candles, RTX 3060 |
| VRAM (SmallJamba inference) | **~0.2 GB** | Minimum footprint |

---

## ğŸš€ Installation

### Prerequisites

| Software | Version | Required |
|:---------|:-------:|:--------:|
| [Python](https://python.org) | 3.12 (3.10+) | âœ… |
| [Node.js](https://nodejs.org) | 20 LTS+ | âœ… |
| NVIDIA GPU + CUDA | RTX 3060+ | âœ… Recommended |
| [Git](https://git-scm.com) | any | Optional |

> SmallJamba can run inference on CPU (~50 ms), but GPU is strongly recommended for training and real-time use (~5 ms).

### Setup

```powershell
# 1. Clone
git clone https://github.com/lukeedIII/Predictor.git
cd Predictor

# 2. Python backend
cd desktop\python_backend
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install -r requirements.txt

# 3. API keys  (create .env â€” only Binance is required)
New-Item .env -ItemType File
# Add to .env:
#   BINANCE_API_KEY=your_key
#   BINANCE_SECRET_KEY=your_secret
#   OPENAI_API_KEY=your_key   (optional â€” Dr. Nexus AI)

# 4. Frontend
cd ..
npm install

# 5. Launch
npm run dev
```

### Train a Model (before first launch)

```powershell
cd desktop\python_backend
.\venv\Scripts\Activate.ps1
python train_mamba.py --arch small --skip-download    # ~6 hrs on RTX 3060
```

### Run Tests

```powershell
cd desktop\python_backend
.\venv\Scripts\Activate.ps1
python -m pytest tests/ -v
# 24 tests â€” label creation, causal integrity, gap detection, HMM ordering,
# PSI drift, Sharpe, champion-challenger config, RQA/TDA guardrails
```

### Reproduce Backtest

```powershell
cd desktop\python_backend
.\venv\Scripts\Activate.ps1
python run_backtest_parallel.py    # all CPU cores
# or
python run_backtest.py             # single-threaded
```

---

## ğŸ—ï¸ Project Structure

```
Predictor/
â”œâ”€â”€ desktop/
â”‚   â”œâ”€â”€ python_backend/        # FastAPI + all ML/quant logic
â”‚   â”‚   â”œâ”€â”€ api_server.py      # Main FastAPI app + boot-gate middleware
â”‚   â”‚   â”œâ”€â”€ predictor.py       # NexusPredictor â€” XGBoost + Jamba SSM ensemble
â”‚   â”‚   â”œâ”€â”€ mamba_model.py     # SmallJamba / LiteJamba / MediumJamba / LargeJamba
â”‚   â”‚   â”œâ”€â”€ train_mamba.py     # Standalone training script (all model sizes)
â”‚   â”‚   â”œâ”€â”€ paper_trader.py    # Thread-safe paper trading engine (RLock)
â”‚   â”‚   â”œâ”€â”€ quant_engine.py    # 16-model institutional quant engine
â”‚   â”‚   â”œâ”€â”€ config.py          # All tuneable parameters
â”‚   â”‚   â”œâ”€â”€ requirements.txt   # Pinned dependencies
â”‚   â”‚   â””â”€â”€ tests/             # 24 pytest tests
â”‚   â””â”€â”€ src/                   # React + TypeScript frontend (Vite)
â”œâ”€â”€ training_kit/              # Standalone training utilities
â”œâ”€â”€ assets/                    # Logo, banner, demo GIF
â””â”€â”€ README.md
```

---

## ğŸ—ºï¸ Changelog

<details>
<summary><b>v7.0.0 â€” Jamba Edition (current)</b></summary>

- ğŸ§  Full Jamba Hybrid SSM implementation (4 sizes: Small / Lite / Medium / Large)
- ğŸ”¥ MoE auxiliary loss propagation fixed (prevents expert collapse)
- ğŸ›¡ï¸ Gradient clipping in all training paths (`max_norm=1.0`)
- ğŸ”’ PaperTrader thread safety â€” `threading.RLock` + bounded deque
- âš¡ FastAPI boot-gate middleware â€” zero startup race conditions
- ğŸ¯ AI Trajectory Overlay on TradingView chart
- ğŸ”Œ WebSocket real-time push (~1s latency, replaces polling)
- ğŸ“Š Multi-Model ensemble scoring

</details>

<details>
<summary><b>v6.x â€” Institutional Alpha Series</b></summary>

- Champion-Challenger deployment gate
- 3-channel drift monitoring (PSI + calibration + prediction distribution)
- Fee-adjusted net-PnL with Binance taker + slippage accounting
- Rolling walk-forward evaluation (K=5 folds)
- XGBoost early stopping
- Regime-based 3-layer trade gating
- Hugging Face Model Sync

</details>

---

## ğŸ›¡ï¸ Security

- **No secrets in code** â€” credentials loaded from `.env` (git-ignored)
- **Paper trading only** â€” no real exchange orders, ever
- **Local-first** â€” model weights, candle data, and trade history stay on your machine
- **Minimal external calls** â€” Binance market data Â· optional AI API Â· optional HF sync

---

## âš ï¸ Disclaimer

Nexus Shadow-Quant is an **educational and research tool**. It is not financial advice. Cryptocurrency markets are highly volatile and unpredictable. Past model performance does not guarantee future results. You are solely responsible for any decisions you make.

---

<div align="center">

**v7.0.0 Jamba Edition**

Built locally with âš¡ by **G-luc**

</div>
